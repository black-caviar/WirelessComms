%% CDMA2000 X1 Voice Channel Simulation
clear all; close all; clc
%% Generate augmented short PN sequence 
% Short PN sequence polynomials 
PNI = 'x^15 + x^13 + x^9 + x^8 + x^7 + x^5 + 1';
PNQ = 'x^15 + x^12 + x^11 + x^10 + x^6 + x^5 + x^4 + x^3 + 1';

% Generate short PN sequence with offset 1
PNIGEN = comm.PNSequence('Polynomial', PNI, 'InitialConditions', 1, ...
    'SamplesPerFrame', 2^15-1, 'Mask', de2bi(1,15));
PNQGEN = comm.PNSequence('Polynomial', PNQ, 'InitialConditions', 1, ...
    'SamplesPerFrame', 2^15-1, 'Mask', de2bi(1,15));

% Augment PN sequence 
% Won't make use of masks here since it is inconventient to keep 
% regenerating the augmented PN sequence
PNSEQ = [augmentPN(PNIGEN()), augmentPN(PNQGEN())];

%% Long PN Sequence 
PNL = [42, 35, 33, 31, 27, 26, 25, 22, 21, 19, 18, 17, 16, 10, 7, 6, 5, 3, 2, 1, 0];
PNLGEN = comm.PNSequence('Polynomial', PNL, 'InitialConditions', 1, ...
'VariableSizeOutput', true, 'MaskSource', 'Input Port', 'MaximumOutputSize', [2^31-1,1]);
% Electronic Serial Number 
ESN = de2bi(0,32);

%% Generate Walsh code 
H = hadamard(64);
W = abs((H-1)./2);
% Stretch Walsh matrix to length of PN sequence 
%longW = repmat(W, [1,length(PNSEQ)/length(W)]);

%% Generate and encode the pilot channel sequence
% Chose some offset for the station sequence 
BS_OFFSET = 300;
SSEQ1 = circshift(PNSEQ, BS_OFFSET * 64);
% The Walsh encoding for the pilot channel is all 0 so I won't apply it
pilotTran = bi2de(SSEQ1);
pilotChan = pskmod(pilotTran, 4, pi/4, 'gray');

% Generate some other pilot channel at a lower power
SSEQ2 = circshift(PNSEQ, 120 * 64);
pilotTran2 = bi2de(SSEQ2);
pilotChan2 = 0.8*pskmod(pilotTran2, 4, pi/4, 'gray');

%% Convert audio to binary data 
% This is a crude method of compressing audio that is not representative
% of the vocoders used in 

testfile = 'testfile.wav';

%audio = audioread('speech_dft_8kHz.wav');
%audio1 = audioread('SpeechDFT-16-8-mono-5secs.wav');
%audiowrite('testfile.wav', audio1, 2^13, 'BitsPerSample', 8);
%audio2 = audioread(testfile);
%play sound
  
intAudio = audioread(testfile, 'native');
audioFrame = audio2frame(intAudio);

%[decodeFrame, errors] = frame2bin(audioFrame);
%newAudio = frame2audio(decodeFrame);

%% Perform convolutional encoding on the audio frames 
% 3.1.3.1.5.1.4Rate 1/2 Convolutional Code
trellis = poly2trellis(9, [753, 561])

% reset the endcoder to 0 at every new frame,
% 3.1.3.15.3 Forward Fundamental Channel Convolutional Encoding
convFrame = zeros(384,length(audioFrame));
for i = 1:length(audioFrame)
    convFrame(:,i) = convenc(audioFrame(:,i)', trellis)';
end

%% Interleaving
% Table 3.1.3.1.8-1. Interleaver Parameters

m = 6;
J = 6;

A = @(i) 2^m * mod(i,J) + bi2de(flip(de2bi(floor(i/J),m)));

interleavedFrame = zeros(size(convFrame));
interleaveMap = zeros(length(convFrame), 1);

for i = [1:384]
    interleavedFrame(A(i-1)+1,:) = convFrame(i,:); 
    interleaveMap(A(i-1)+1) = i-1;
end

%% Modulate with long PN code 
% Split voice channel into 8 channel streams
% PN chips are same of the same rate as the data 
reset(PNLGEN);
voiceChans = zeros(384 * length(interleavedFrame)/8, 8);
scrambleChans = zeros(size(voiceChans));
bitsLPN = PNLGEN(maskPNLC(ESN), 64*length(scrambleChans));
deciLPN = bitsLPN(1:64:end)';
    
for i = 1:8
    voiceChans(:,i) = reshape(interleavedFrame(:,i:8:end), [], 1);
    %scrambleChans(:,i) = xor(deciLPN(:,i), voiceChans(:,i));
end
scrambleChans = cast(xor(deciLPN', voiceChans), 'double');
%% Encode with Walsh Code 
% Increase code rate to 1.2288 MCPS 
% 1228800/19200 = 64
% 64 Chips per bit are used to spread this particular transmission 
expandedChans = rectpulse(scrambleChans, 64);
spreadCodeW = zeros(size(expandedChans));
for i = 0:length(scrambleChans)-1
    varRange = 64*i+1:64*i+64;
    spreadCodeW(varRange,:) = xor(W([10:17],:)', expandedChans(varRange,:));
end

%% Modulate to baseband
% Map bits to symbols 
mappedSignal = qammod(spreadCodeW, 2);
unifiedSignal = sum(mappedSignal,2);

extendPNSEQ = qammod(repmat(PNSEQ, [length(unifiedSignal)/length(PNSEQ),1]),2);
basebandSignal = unifiedSignal .* extendPNSEQ;

%% Transmit the baseband here 
% AWGN stuff here

%% Decode spreading codes

rawSignal = mean(basebandSignal .* extendPNSEQ, 2);
recoveredRX = qamdemod(codeCC(rawSignal, H(10:17,:)')/64,2);
descrambledRX = xor(recoveredRX, deciLPN');
interleaveRX = zeros(size(interleavedFrame));
for i = 1:8 
    interleaveRX(:,i:8:end) = reshape(descrambledRX(:,i), 384, []);
end

% interpolate codes into interleaved data
% interleaving is performed on a frame-by-frame basis
deinterleavedRX = zeros(size(interleaveRX));
for i = [1:384]
    h = interleaveMap(i);
    deinterleavedRX(h+1,:) = interleaveRX(i,:); 
end

% good up to convolutional encoder

%% Undo convolutional coding

frameRX = zeros(172, length(deinterleavedRX));
for i = 1:length(

% reset the endcoder to 0 at every new frame,
% 3.1.3.15.3 Forward Fundamental Channel Convolutional Encoding
convFrame = zeros(384,length(audioFrame));
for i = 1:length(audioFrame)
    convFrame(:,i) = convenc(audioFrame(:,i)', trellis)';
end
    
%% Transmit 

%out = awgn(pilotChan, 10);
out = awgn(pilotChan + pilotChan2, 10);
%figure;
scatterplot(out, 1, 0, 'b*');

%% Receive 

%refSEQ = pskmod(bi2de(PNSEQ), 4, pi/4, 'gray');

rx = pskdemod(out, 4, pi/4, 'gray');
rxPN = de2bi(rx);
%iCorr = xcorr(PNISEQ, rxPN(:,1));
%qCorr = xcorr(PNQSEQ, rxPN(:,2));
%iCorr = cconv(PNISEQ, rxPN(:,1));

%iCorr = correlate(PNSEQ, rxPN);
iCorr = correlate(PNSEQ, rxPN);
figure;
plot(iCorr);
legend;
figure;
plot(correlate(PNSEQ, SSEQ2));

function frame = audio2frame(audio)
    % Convert integer audio matrix to valid 192 bit frames
    binAudio = de2bi(audio)';
    vecAudio = reshape(binAudio(:), 1, []);
    
    trimLen = floor(length(vecAudio)/172);
    trimAudio = vecAudio(1:trimLen*172);
    rawFrame = reshape(trimAudio, 172, []);
    %padFrame = [zeros([1,length(rawFrame)]); rawFrame];
    padFrame = rawFrame;
    
    %trimLen = floor(length(audio)*8/168)*21;
    %trimAudio = audio(1:trimLen);
    %binAudio = de2bi(trimA udio)';
    
    % I could fit 171 bits worth of audio into every frame, but that 
    % is a strange and unweildy value. Use 168 bits instead and pad 
    %rawFrame = cast(reshape(binAudio(:),168,[]), 'double');
    %padFrame = [zeros([1,length(rawF = audio2frame(intAudio);
%nrame)]); rawFrame; zeros([3,length(rawFrame)])];
    
    poly = [1,1,1,1,1,0,0,0,1,0,0,1,1];
    crcgenerator = crc.generator(poly)
    
    crcFrame = generate(crcgenerator, padFrame);
    % 3.1.3.15.2.2 Forward Fundamental Channel Encoder Tail Bits
    frame = [crcFrame; zeros([8,length(crcFrame)])];
    frame = cast(frame, 'double');
end

function [rawFrame, errorFrames] = frame2bin(frame)
    %remove padding from end 
    frame(185:192,:) = [];
    
    % Figure 3.1.3.1.4.1.2-1
    poly = [1,1,1,1,1,0,0,0,1,0,0,1,1];
    crcdetect = crc.detector(poly)
    
    [rawFrame, errorFrames] = detect(crcdetect, frame);
    %rawFrame(1,:) = [];
end

function intAudio = frame2audio(frame)
    vecAudio = reshape(frame(:), 1, []);
    padLen = ceil(length(vecAudio)/8)*8 - length(vecAudio)
    padAudio = [vecAudio, zeros([1,padLen])];
    
    binAudio = reshape(padAudio, 8, []);
    intAudio = bi2de(binAudio');
end

function rate = correlate(ref, test)
    if (size(ref) ~= size(test))
        error("Input arguments must have same dimensions");
    end
    rate = zeros(size(test));
    for i = 1:length(test)
        shift = circshift(ref,i);
        rate(i,:) = sum(shift.*test);
    end

end